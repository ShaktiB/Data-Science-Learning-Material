{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")[:80000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of x=(80000, 28), y=(80000,), #Fraud Cases = 196\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "print(f\"Shapes of x={x.shape}, y={y.shape}, #Fraud Cases = {y.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This data is imbalanced -> # of faudses cases vs # not fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0:1,1:2}, max_iter = 1000)\n",
    "mod.fit(x,y).predict(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"\n",
       "        Return the mean accuracy on the given test data and labels.\n",
       "\n",
       "        In multi-label classification, this is the subset accuracy\n",
       "        which is a harsh metric since you require for each sample that\n",
       "        each label set be correctly predicted.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like of shape (n_samples, n_features)\n",
       "            Test samples.\n",
       "\n",
       "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "            True labels for X.\n",
       "\n",
       "        sample_weight : array-like of shape (n_samples,), default=None\n",
       "            Sample weights.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        score : float\n",
       "            Mean accuracy of self.predict(X) wrt. y.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sbhati\\anaconda3\\lib\\site-packages\\sklearn\\base.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??mod.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid = {'class_weight': [{0:1, 1:v} for v in range(1,4)]}, \n",
    "    cv = 4,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.215928</td>\n",
       "      <td>0.755951</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1}}</td>\n",
       "      <td>0.99405</td>\n",
       "      <td>0.99835</td>\n",
       "      <td>0.99945</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.902000</td>\n",
       "      <td>1.266062</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2}}</td>\n",
       "      <td>0.99025</td>\n",
       "      <td>0.99840</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>0.99805</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.625607</td>\n",
       "      <td>0.309669</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3}}</td>\n",
       "      <td>0.98730</td>\n",
       "      <td>0.99845</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>0.99815</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.215928      0.755951         0.012534        0.003594   \n",
       "1       3.902000      1.266062         0.007896        0.001477   \n",
       "2       2.625607      0.309669         0.007394        0.001714   \n",
       "\n",
       "  param_class_weight                          params  split0_test_score  \\\n",
       "0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}            0.99405   \n",
       "1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}            0.99025   \n",
       "2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}            0.98730   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.99835            0.99945            0.99780         0.997413   \n",
       "1            0.99840            0.99960            0.99805         0.996575   \n",
       "2            0.99845            0.99960            0.99815         0.995875   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.002030                1  \n",
       "1        0.003697                2  \n",
       "2        0.004980                3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7682119205298014"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y, grid.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5918367346938775"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y, grid.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iternation 2 w/ Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid = {'class_weight': [{0:1, 1:v} for v in range(1,4)]}, \n",
    "    scoring={'precision':make_scorer(precision_score), 'recall_score':make_scorer(recall_score)},\n",
    "    refit = 'precision', # Telling Python which metric you want to optimize\n",
    "    return_train_score=True,\n",
    "    cv = 4,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score),\n",
       "                      'recall_score': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_recall_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>std_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>split0_train_recall_score</th>\n",
       "      <th>split1_train_recall_score</th>\n",
       "      <th>split2_train_recall_score</th>\n",
       "      <th>split3_train_recall_score</th>\n",
       "      <th>mean_train_recall_score</th>\n",
       "      <th>std_train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.735719</td>\n",
       "      <td>1.195462</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1}}</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.545918</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.668367</td>\n",
       "      <td>0.127301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.514259</td>\n",
       "      <td>1.331143</td>\n",
       "      <td>0.056772</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2}}</td>\n",
       "      <td>0.190678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.297672</td>\n",
       "      <td>2</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.736395</td>\n",
       "      <td>0.095889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.828712</td>\n",
       "      <td>0.402053</td>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3}}</td>\n",
       "      <td>0.154882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>0.281816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.680272</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.076568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.735719      1.195462         0.056650        0.002722   \n",
       "1       4.514259      1.331143         0.056772        0.014615   \n",
       "2       3.828712      0.402053         0.037350        0.004547   \n",
       "\n",
       "  param_class_weight                          params  split0_test_precision  \\\n",
       "0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}               0.281250   \n",
       "1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}               0.190678   \n",
       "2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}               0.154882   \n",
       "\n",
       "   split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                    1.0               0.952381               0.857143  ...   \n",
       "1                    1.0               0.955556               0.812500  ...   \n",
       "2                    1.0               0.955556               0.800000  ...   \n",
       "\n",
       "   split3_test_recall_score  mean_test_recall_score  std_test_recall_score  \\\n",
       "0                  0.122449                0.545918               0.331397   \n",
       "1                  0.265306                0.602041               0.297672   \n",
       "2                  0.326531                0.627551               0.281816   \n",
       "\n",
       "   rank_test_recall_score  split0_train_recall_score  \\\n",
       "0                       3                   0.863946   \n",
       "1                       2                   0.870748   \n",
       "2                       1                   0.870748   \n",
       "\n",
       "   split1_train_recall_score  split2_train_recall_score  \\\n",
       "0                   0.585034                   0.530612   \n",
       "1                   0.659864                   0.632653   \n",
       "2                   0.714286                   0.680272   \n",
       "\n",
       "   split3_train_recall_score  mean_train_recall_score  std_train_recall_score  \n",
       "0                   0.693878                 0.668367                0.127301  \n",
       "1                   0.782313                 0.736395                0.095889  \n",
       "2                   0.816327                 0.770408                0.076568  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iteration 3**\n",
    "- Increase Cross Validations\n",
    "- Increase range for class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid = {'class_weight': [{0:1, 1:v} for v in np.linspace(1,20, 30)]}, \n",
    "    scoring={'precision':make_scorer(precision_score), 'recall_score':make_scorer(recall_score)},\n",
    "    refit = 'precision', # Telling Python which metric you want to optimize\n",
    "    return_train_score=True,\n",
    "    cv = 10,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_recall_score</th>\n",
       "      <th>split3_train_recall_score</th>\n",
       "      <th>split4_train_recall_score</th>\n",
       "      <th>split5_train_recall_score</th>\n",
       "      <th>split6_train_recall_score</th>\n",
       "      <th>split7_train_recall_score</th>\n",
       "      <th>split8_train_recall_score</th>\n",
       "      <th>split9_train_recall_score</th>\n",
       "      <th>mean_train_recall_score</th>\n",
       "      <th>std_train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.459089</td>\n",
       "      <td>1.080728</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.935615</td>\n",
       "      <td>0.632611</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.050286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.659381</td>\n",
       "      <td>0.619272</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.453383</td>\n",
       "      <td>0.480236</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.436573</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.771498</td>\n",
       "      <td>0.037959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.588105</td>\n",
       "      <td>0.617191</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.670359</td>\n",
       "      <td>0.619388</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.812327</td>\n",
       "      <td>0.021063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.574319</td>\n",
       "      <td>1.022666</td>\n",
       "      <td>0.025367</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.017190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.655176</td>\n",
       "      <td>1.100321</td>\n",
       "      <td>0.022311</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.190244</td>\n",
       "      <td>1.255142</td>\n",
       "      <td>0.027623</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.844665</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.860156</td>\n",
       "      <td>0.861798</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.029098</td>\n",
       "      <td>1.258359</td>\n",
       "      <td>0.028426</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.070634</td>\n",
       "      <td>1.354806</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.395942</td>\n",
       "      <td>1.935138</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>0.021316</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.855441</td>\n",
       "      <td>0.011414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.892270</td>\n",
       "      <td>0.923686</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856009</td>\n",
       "      <td>0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.293159</td>\n",
       "      <td>1.343712</td>\n",
       "      <td>0.022961</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856577</td>\n",
       "      <td>0.011881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.657434</td>\n",
       "      <td>0.870474</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.859415</td>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.444174</td>\n",
       "      <td>0.986187</td>\n",
       "      <td>0.026070</td>\n",
       "      <td>0.017453</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.096098</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.864513</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.245430</td>\n",
       "      <td>1.343458</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866214</td>\n",
       "      <td>0.010798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.982068</td>\n",
       "      <td>0.911923</td>\n",
       "      <td>0.022309</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.011092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.537417</td>\n",
       "      <td>1.126820</td>\n",
       "      <td>0.024214</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.010509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.171196</td>\n",
       "      <td>0.807607</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.142252</td>\n",
       "      <td>1.066028</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.212510</td>\n",
       "      <td>0.727018</td>\n",
       "      <td>0.025819</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.211299</td>\n",
       "      <td>0.710423</td>\n",
       "      <td>0.024214</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869617</td>\n",
       "      <td>0.009789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.975090</td>\n",
       "      <td>1.302279</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870185</td>\n",
       "      <td>0.010851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.463517</td>\n",
       "      <td>0.872421</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.059240</td>\n",
       "      <td>0.577712</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.826181</td>\n",
       "      <td>0.460450</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873588</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.459089      1.080728         0.022008        0.006768   \n",
       "1        3.935615      0.632611         0.018449        0.006785   \n",
       "2        3.659381      0.619272         0.017998        0.005718   \n",
       "3        3.453383      0.480236         0.016995        0.004173   \n",
       "4        3.436573      0.581563         0.019401        0.005343   \n",
       "5        3.588105      0.617191         0.021206        0.007630   \n",
       "6        3.670359      0.619388         0.016644        0.002790   \n",
       "7        3.574319      1.022666         0.025367        0.018726   \n",
       "8        4.655176      1.100321         0.022311        0.006440   \n",
       "9        5.190244      1.255142         0.027623        0.015330   \n",
       "10       4.860156      0.861798         0.023712        0.007905   \n",
       "11       5.029098      1.258359         0.028426        0.009895   \n",
       "12       5.070634      1.354806         0.024615        0.009642   \n",
       "13       5.395942      1.935138         0.037650        0.021316   \n",
       "14       4.892270      0.923686         0.023814        0.010297   \n",
       "15       4.293159      1.343712         0.022961        0.009882   \n",
       "16       4.657434      0.870474         0.035043        0.022363   \n",
       "17       4.444174      0.986187         0.026070        0.017453   \n",
       "18       5.096098      0.983217         0.025919        0.007175   \n",
       "19       5.245430      1.343458         0.032435        0.012571   \n",
       "20       4.982068      0.911923         0.022309        0.002656   \n",
       "21       5.537417      1.126820         0.024214        0.010490   \n",
       "22       5.171196      0.807607         0.026270        0.009404   \n",
       "23       5.142252      1.066028         0.024113        0.009723   \n",
       "24       5.212510      0.727018         0.025819        0.008875   \n",
       "25       4.211299      0.710423         0.024214        0.008202   \n",
       "26       4.975090      1.302279         0.025418        0.011436   \n",
       "27       4.463517      0.872421         0.022217        0.006717   \n",
       "28       4.059240      0.577712         0.020604        0.005392   \n",
       "29       3.826181      0.460450         0.017246        0.004590   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               1.000000   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               1.000000   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               1.000000   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               1.000000   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               1.000000   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               1.000000   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               1.000000   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               1.000000   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.944444   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.944444   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.944444   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.944444   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.944444   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.894737   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.850000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.850000   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.857143   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.857143   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.857143   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.818182   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.818182   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.818182   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.818182   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.782609   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.782609   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.782609   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.782609   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.782609   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.782609   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.782609   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.463415               0.583333               1.000000  ...   \n",
       "1                0.463415               0.583333               1.000000  ...   \n",
       "2                0.463415               0.583333               1.000000  ...   \n",
       "3                0.452381               0.583333               1.000000  ...   \n",
       "4                0.452381               0.583333               1.000000  ...   \n",
       "5                0.452381               0.583333               1.000000  ...   \n",
       "6                0.452381               0.583333               1.000000  ...   \n",
       "7                0.452381               0.583333               1.000000  ...   \n",
       "8                0.452381               0.583333               0.947368  ...   \n",
       "9                0.452381               0.583333               0.947368  ...   \n",
       "10               0.452381               0.583333               0.947368  ...   \n",
       "11               0.452381               0.583333               0.947368  ...   \n",
       "12               0.441860               0.583333               0.947368  ...   \n",
       "13               0.431818               0.560000               0.947368  ...   \n",
       "14               0.431818               0.560000               0.947368  ...   \n",
       "15               0.431818               0.560000               0.947368  ...   \n",
       "16               0.431818               0.560000               0.947368  ...   \n",
       "17               0.431818               0.576923               0.947368  ...   \n",
       "18               0.413043               0.576923               0.947368  ...   \n",
       "19               0.413043               0.576923               0.947368  ...   \n",
       "20               0.413043               0.576923               0.947368  ...   \n",
       "21               0.404255               0.576923               0.947368  ...   \n",
       "22               0.387755               0.576923               0.947368  ...   \n",
       "23               0.380000               0.576923               0.947368  ...   \n",
       "24               0.380000               0.555556               0.947368  ...   \n",
       "25               0.380000               0.555556               0.947368  ...   \n",
       "26               0.365385               0.535714               0.947368  ...   \n",
       "27               0.345455               0.535714               0.947368  ...   \n",
       "28               0.345455               0.535714               0.947368  ...   \n",
       "29               0.339286               0.535714               0.947368  ...   \n",
       "\n",
       "    split2_train_recall_score  split3_train_recall_score  \\\n",
       "0                    0.627119                   0.548023   \n",
       "1                    0.683616                   0.627119   \n",
       "2                    0.740113                   0.683616   \n",
       "3                    0.785311                   0.706215   \n",
       "4                    0.824859                   0.740113   \n",
       "5                    0.841808                   0.768362   \n",
       "6                    0.847458                   0.802260   \n",
       "7                    0.847458                   0.813559   \n",
       "8                    0.847458                   0.824859   \n",
       "9                    0.853107                   0.830508   \n",
       "10                   0.858757                   0.841808   \n",
       "11                   0.858757                   0.841808   \n",
       "12                   0.870056                   0.841808   \n",
       "13                   0.870056                   0.841808   \n",
       "14                   0.870056                   0.841808   \n",
       "15                   0.870056                   0.841808   \n",
       "16                   0.870056                   0.841808   \n",
       "17                   0.875706                   0.853107   \n",
       "18                   0.881356                   0.853107   \n",
       "19                   0.881356                   0.858757   \n",
       "20                   0.881356                   0.858757   \n",
       "21                   0.881356                   0.858757   \n",
       "22                   0.881356                   0.858757   \n",
       "23                   0.881356                   0.858757   \n",
       "24                   0.881356                   0.858757   \n",
       "25                   0.881356                   0.864407   \n",
       "26                   0.881356                   0.864407   \n",
       "27                   0.881356                   0.864407   \n",
       "28                   0.881356                   0.864407   \n",
       "29                   0.881356                   0.864407   \n",
       "\n",
       "    split4_train_recall_score  split5_train_recall_score  \\\n",
       "0                    0.573864                   0.573864   \n",
       "1                    0.670455                   0.647727   \n",
       "2                    0.710227                   0.698864   \n",
       "3                    0.744318                   0.732955   \n",
       "4                    0.755682                   0.744318   \n",
       "5                    0.778409                   0.789773   \n",
       "6                    0.789773                   0.818182   \n",
       "7                    0.829545                   0.829545   \n",
       "8                    0.846591                   0.835227   \n",
       "9                    0.846591                   0.835227   \n",
       "10                   0.852273                   0.840909   \n",
       "11                   0.857955                   0.846591   \n",
       "12                   0.857955                   0.846591   \n",
       "13                   0.857955                   0.846591   \n",
       "14                   0.857955                   0.852273   \n",
       "15                   0.857955                   0.852273   \n",
       "16                   0.863636                   0.852273   \n",
       "17                   0.869318                   0.852273   \n",
       "18                   0.869318                   0.852273   \n",
       "19                   0.869318                   0.857955   \n",
       "20                   0.875000                   0.857955   \n",
       "21                   0.875000                   0.857955   \n",
       "22                   0.875000                   0.863636   \n",
       "23                   0.875000                   0.863636   \n",
       "24                   0.875000                   0.863636   \n",
       "25                   0.875000                   0.863636   \n",
       "26                   0.875000                   0.863636   \n",
       "27                   0.875000                   0.875000   \n",
       "28                   0.875000                   0.875000   \n",
       "29                   0.875000                   0.875000   \n",
       "\n",
       "    split6_train_recall_score  split7_train_recall_score  \\\n",
       "0                    0.562500                   0.613636   \n",
       "1                    0.630682                   0.687500   \n",
       "2                    0.687500                   0.715909   \n",
       "3                    0.715909                   0.755682   \n",
       "4                    0.727273                   0.778409   \n",
       "5                    0.772727                   0.789773   \n",
       "6                    0.801136                   0.801136   \n",
       "7                    0.812500                   0.806818   \n",
       "8                    0.823864                   0.829545   \n",
       "9                    0.829545                   0.835227   \n",
       "10                   0.835227                   0.835227   \n",
       "11                   0.835227                   0.846591   \n",
       "12                   0.835227                   0.852273   \n",
       "13                   0.835227                   0.863636   \n",
       "14                   0.835227                   0.863636   \n",
       "15                   0.835227                   0.863636   \n",
       "16                   0.840909                   0.863636   \n",
       "17                   0.840909                   0.869318   \n",
       "18                   0.846591                   0.869318   \n",
       "19                   0.852273                   0.869318   \n",
       "20                   0.852273                   0.869318   \n",
       "21                   0.852273                   0.869318   \n",
       "22                   0.852273                   0.869318   \n",
       "23                   0.852273                   0.869318   \n",
       "24                   0.852273                   0.869318   \n",
       "25                   0.852273                   0.869318   \n",
       "26                   0.852273                   0.869318   \n",
       "27                   0.857955                   0.869318   \n",
       "28                   0.857955                   0.869318   \n",
       "29                   0.857955                   0.869318   \n",
       "\n",
       "    split8_train_recall_score  split9_train_recall_score  \\\n",
       "0                    0.636364                   0.607955   \n",
       "1                    0.698864                   0.687500   \n",
       "2                    0.744318                   0.727273   \n",
       "3                    0.772727                   0.738636   \n",
       "4                    0.784091                   0.761364   \n",
       "5                    0.795455                   0.772727   \n",
       "6                    0.818182                   0.789773   \n",
       "7                    0.835227                   0.818182   \n",
       "8                    0.857955                   0.829545   \n",
       "9                    0.863636                   0.846591   \n",
       "10                   0.863636                   0.846591   \n",
       "11                   0.869318                   0.852273   \n",
       "12                   0.869318                   0.857955   \n",
       "13                   0.869318                   0.857955   \n",
       "14                   0.869318                   0.857955   \n",
       "15                   0.875000                   0.857955   \n",
       "16                   0.880682                   0.863636   \n",
       "17                   0.880682                   0.863636   \n",
       "18                   0.886364                   0.863636   \n",
       "19                   0.886364                   0.863636   \n",
       "20                   0.886364                   0.863636   \n",
       "21                   0.886364                   0.863636   \n",
       "22                   0.886364                   0.863636   \n",
       "23                   0.886364                   0.869318   \n",
       "24                   0.886364                   0.869318   \n",
       "25                   0.886364                   0.875000   \n",
       "26                   0.892045                   0.875000   \n",
       "27                   0.897727                   0.875000   \n",
       "28                   0.897727                   0.875000   \n",
       "29                   0.897727                   0.875000   \n",
       "\n",
       "    mean_train_recall_score  std_train_recall_score  \n",
       "0                  0.612185                0.054733  \n",
       "1                  0.680239                0.050286  \n",
       "2                  0.724454                0.043881  \n",
       "3                  0.749978                0.039589  \n",
       "4                  0.771498                0.037959  \n",
       "5                  0.792485                0.029289  \n",
       "6                  0.812327                0.021063  \n",
       "7                  0.827080                0.017190  \n",
       "8                  0.838431                0.013974  \n",
       "9                  0.844665                0.012015  \n",
       "10                 0.848064                0.010502  \n",
       "11                 0.852038                0.009997  \n",
       "12                 0.854305                0.011103  \n",
       "13                 0.855441                0.011414  \n",
       "14                 0.856009                0.011097  \n",
       "15                 0.856577                0.011881  \n",
       "16                 0.859415                0.011778  \n",
       "17                 0.862811                0.011843  \n",
       "18                 0.864513                0.012530  \n",
       "19                 0.866214                0.010798  \n",
       "20                 0.866782                0.011092  \n",
       "21                 0.867347                0.010509  \n",
       "22                 0.867915                0.010133  \n",
       "23                 0.868484                0.010036  \n",
       "24                 0.868484                0.010036  \n",
       "25                 0.869617                0.009789  \n",
       "26                 0.870185                0.010851  \n",
       "27                 0.872458                0.011025  \n",
       "28                 0.872458                0.011025  \n",
       "29                 0.873588                0.010104  \n",
       "\n",
       "[30 rows x 56 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x,y)\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
